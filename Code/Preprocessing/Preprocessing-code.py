# -*- coding: utf-8 -*-
"""Another copy of Code for equalizing and pre for claassfication welding fects.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XZ2UuQSvJ8cmxTDk1eiEClqd9I3sgwtD
"""

from google.colab import drive
drive.mount('/content/drive')

"""## Importing Liabraries"""

!pip install tensorflow opencv-python matplotlib scikit-learn

"""## Data Collection"""

import os
import cv2
import numpy as np
import pandas as pd

# Define paths
data_dir = '/content/drive/MyDrive/Defects_welding/Original'  # Path to the images folder
categories = ['Overweld', 'Porosity','Undercut', 'Underfilled']

# Initialize lists to hold the images and labels
images = []
labels = []

# Label encoding
label_map = {category: index for index, category in enumerate(categories)}

# Load images and encode labels
for category in categories:
    category_path = os.path.join(data_dir, category)
    for img_name in os.listdir(category_path):
        img_path = os.path.join(category_path, img_name)
        # Read and resize image
        img = cv2.imread(img_path)
        img = cv2.resize(img, (224, 224))  # Resize to match model input
        images.append(img)
        labels.append(label_map[category])

# Convert to numpy arrays
images = np.array(images)
labels = np.array(labels)

# Create a DataFrame for easy manipulation
data = pd.DataFrame({'image': list(images), 'label': labels})

data.head()

# @title label
from matplotlib import pyplot as plt
data['label'].plot(kind='hist', bins=20, title='label')
plt.gca().spines[['top', 'right',]].set_visible(False)

from matplotlib import pyplot as plt
categories = ['Overweld', 'Porosity', 'Undercut', 'Underfilled']
label_map = {0: 'Overweld', 1: 'Porosity', 2: 'Undercut', 3: 'Underfilled'}

# Plot the histogram
data['label'].plot(kind='hist', bins=20,title='Building Defects')
plt.gca().spines[['top', 'right']].set_visible(False)

# Set the x-axis tick labels to category names
plt.xticks(ticks=range(len(categories)), labels=categories)

# Show the plot
plt.show()

"""## Data Augmentation"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Initialize ImageDataGenerator for augmentation
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Check the size of the original dataset
original_size = len(images)
print(f"Original dataset size: {original_size} images")

import os
import cv2
import numpy as np

# Data directories
#data_dir = 'OriginalData'  # Directory containing original images
#augmented_data_dir = 'Augmented_2'  # Directory for augmented images
# Assuming you have the paths defined
original_images_path = '/content/drive/MyDrive/Defects_welding/Original'
categories= os.listdir(original_images_path)

# Path to Google Drive (adjust if necessary)
augmented_images_path = '/content/drive/MyDrive/Defects_welding/Augmented'

# Create augmented images path if it doesn't exist
if not os.path.exists(augmented_images_path):
    os.makedirs(augmented_images_path)

# Data augmentation parameters
target_count_per_category = 400  # Total target count per category (original + augmented)

# Data augmentation configuration
datagen = ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

categories = ['Overweld', 'Porosity','Undercut', 'Underfilled']  # Define your categories

# Loop through each category
for category in categories:
    category_path = os.path.join('/content/drive/MyDrive/Defects_welding/Original', category)
    augmented_category_path = os.path.join(augmented_images_path, category)

    # Create folder for augmented images if it doesn't exist
    os.makedirs(augmented_category_path, exist_ok=True)

    # Get the number of original and already augmented images
    current_images = len(os.listdir(category_path))  # Number of original images
    augmented_images = len(os.listdir(augmented_category_path))  # Number of already augmented images

    # Total images already present (original + augmented)
    total_existing_images = current_images + augmented_images

    # Calculate how many more images are needed to reach the target count
    needed_images = target_count_per_category - total_existing_images

    # If needed_images is greater than 0, proceed with augmentation
    if needed_images > 0:
        original_images_list = os.listdir(category_path)  # List of original images

        # Loop through original images and generate augmented images
        for img_name in original_images_list:
            img_path = os.path.join(category_path, img_name)
            img = cv2.imread(img_path)
            img = cv2.resize(img, (224, 224))  # Resize to match model input size

            # Reshape the image for the generator
            img = img.reshape((1,) + img.shape)  # Add batch dimension

            # Generate augmented images and save them
            for batch in datagen.flow(img, batch_size=1, save_to_dir=augmented_category_path,
                                       save_prefix='aug', save_format='jpeg'):
                augmented_images += 1
                if augmented_images + current_images >= target_count_per_category:
                    break

            # Stop augmenting if we have reached the target number of images
            if augmented_images + current_images >= target_count_per_category:
                break

    # Print the count of images for each category
    total_count = current_images + augmented_images  # Total images in the category
    print(f"{category} has been augmented to {total_count} images (Total after augmentation: {augmented_images} new images).")

# Check the total dataset size after augmentation
total_images = 0
for category in categories:
    count = len(os.listdir(os.path.join(augmented_images_path, category))) + len(os.listdir(os.path.join('/content/drive/MyDrive/Defects_welding/Original', category)))
    total_images += count
    print(f"{category}: {count} images")

print(f"Total dataset size after augmentation: {total_images} images")

# Data augmentation parameters
additional_images_needed = 4  # We need 4 more images for the Porosity category

# Data augmentation configuration
datagen = ImageDataGenerator(
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Augment only the Porosity category
category = 'Porosity'
category_path = os.path.join(original_images_path, category)
augmented_category_path = os.path.join(augmented_images_path, category)

# Create folder for augmented images if it doesn't exist
os.makedirs(augmented_category_path, exist_ok=True)

# Get the list of original images
original_images_list = os.listdir(category_path)

# Loop through original images and generate augmented images
for img_name in original_images_list:
    img_path = os.path.join(category_path, img_name)
    img = cv2.imread(img_path)
    img = cv2.resize(img, (224, 224))  # Resize to match model input size

    # Reshape the image for the generator
    img = img.reshape((1,) + img.shape)  # Add batch dimension

    # Generate augmented images and save them
    i = 0
    for batch in datagen.flow(img, batch_size=1, save_to_dir=augmented_category_path,
                              save_prefix='aug', save_format='jpeg'):
        i += 1
        if i >= additional_images_needed:
            break

    # Stop augmenting after 4 images are added
    additional_images_needed -= i
    if additional_images_needed <= 0:
        break

# Check and print the count of images in the Porosity category after augmentation
total_images = len(os.listdir(augmented_category_path))
print(f"{category} has been augmented to {total_images} images (4 more images added).")

# Final count check for all categories - in Augmented Dataset
total_images = 0
for category in ['Overweld','Porosity', 'Undercut',  'Underfilled']:
    count = len(os.listdir(os.path.join(augmented_images_path, category)))
    total_images += count
    print(f"{category}: {count} images")

print(f"Total dataset size after augmentation: {total_images} images")

import os
import cv2
import numpy as np

# Define your paths
original_images_path = '/content/drive/MyDrive/Defects_welding/Original'
augmented_images_path = '/content/drive/MyDrive/Defects_welding/Augmented'
categories = [ 'Overweld', 'Porosity','Undercut', 'Underfilled']
label_map = {0: 'Overweld', 1: 'Porosity', 2: 'Undercut', 3: 'Underfilled'}

# Initialize lists to hold the original and augmented images and labels
original_images = []
original_labels = []
augmented_images = []
augmented_labels = []

# Load original images and labels
for category in categories:
    category_path = os.path.join(original_images_path, category)
    label = list(label_map.keys())[list(label_map.values()).index(category)]

    for img_name in os.listdir(category_path):
        img_path = os.path.join(category_path, img_name)
        img = cv2.imread(img_path)
        if img is not None:
            img = cv2.resize(img, (224, 224))  # Resize to match model input
            original_images.append(img)
            original_labels.append(label)

# Convert to numpy arrays
original_images = np.array(original_images)
original_labels = np.array(original_labels)

# Load augmented images and labels
for category in categories:
    category_path = os.path.join(augmented_images_path, category)
    label = list(label_map.keys())[list(label_map.values()).index(category)]

    for img_name in os.listdir(category_path):
        img_path = os.path.join(category_path, img_name)
        img = cv2.imread(img_path)
        if img is not None:
            img = cv2.resize(img, (224, 224))  # Resize to match model input
            augmented_images.append(img)
            augmented_labels.append(label)

# Convert to numpy arrays
augmented_images = np.array(augmented_images)
augmented_labels = np.array(augmented_labels)

# Combine original and augmented images and labels
combined_images = np.concatenate((original_images, augmented_images), axis=0)
combined_labels = np.concatenate((original_labels, augmented_labels), axis=0)

# Print final dataset counts for verification
total_images = 0
for category in categories:
    count = len(os.listdir(os.path.join(augmented_images_path, category)))
    total_images += count
    print(f"{category}: {count} images")

print(f"Total dataset size after augmentation: {total_images} images")

# Print combined dataset size
print(f"Combined dataset size: {len(combined_images)} images")
print(f"Combined labels size: {len(combined_labels)} labels")

# Convert to numpy arrays
image = np.array(combined_images)
label = np.array(combined_labels)

# Create a DataFrame for easy manipulation
data = pd.DataFrame({'image': list(image), 'label': label})

from matplotlib import pyplot as plt
categories = ['Overweld', 'Porosity', 'Undercut', 'Underfilled']
label_map = {0: 'Overweld', 1: 'Porosity', 2: 'Undercut', 3: 'Underfilled'}

# Plot the histogram
data['label'].plot(kind='hist', bins=20,title='Building Defects')
plt.gca().spines[['top', 'right']].set_visible(False)

# Set the x-axis tick labels to category names
plt.xticks(ticks=range(len(categories)), labels=categories)

# Show the plot
plt.show()

# Count occurrences of each label
label_counts = data['label'].value_counts()
print(label_counts)
print("------------------")
print(label_map)

import os
import cv2

# Define your categories and map them to labels
categories = ['Overweld', 'Porosity', 'Undercut', 'Underfilled']
label_map = {0: 'Overweld', 1: 'Porosity', 2: 'Undercut', 3: 'Underfilled'}  # Adjust this if labels are different

# Define the path where you want to save the combined images
output_path = '/content/drive/MyDrive/Defects_welding/Combined'

# Create directories for each category if they don't exist
for category in categories:
    category_dir = os.path.join(output_path, category)
    if not os.path.exists(category_dir):
        os.makedirs(category_dir)

# Save combined images to their respective label folders
for i, img in enumerate(combined_images):
    label = combined_labels[i]  # Get the label for the image
    category_name = label_map[label]  # Map the label to the category name
    category_path = os.path.join(output_path, category_name)  # Path to the correct folder

    # Save the image to the folder
    img_name = f'image_{i}.jpg'  # Create a unique name for the image
    img_path = os.path.join(category_path, img_name)

    # Write image to the folder
    cv2.imwrite(img_path, img)

print("Images saved to respective folders based on their labels.")

print(original_images[0].shape)  # Check the shape of the first image
print(augmented_images[0].shape)

combined_images.shape

combined_labels.shape

print(len(combined_images), len(combined_labels))

"""## Data Analysis"""

import matplotlib.pyplot as plt

# Function to display images
def display_images(images, labels, num_images=5):
    plt.figure(figsize=(15, 10))
    for i in range(num_images):
        plt.subplot(1, num_images, i + 1)
        plt.imshow(images[i].astype('uint8'))  # Convert to uint8 for display
        plt.title(f"Label: {labels[i]}")
        plt.axis('off')
    plt.show()

# Display sample images from the combined dataset
display_images(combined_images, combined_labels, num_images=4)



combined_labels

"""## Split the Data"""

from sklearn.model_selection import train_test_split

# Split combined dataset into training (70%), validation (20%), and test (10%)
X_train_val, X_test, y_train_val, y_test = train_test_split(combined_images, combined_labels, test_size=0.1, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)

# Print sizes of the splits
print(f"Training dataset size: {len(X_train)} images")
print(f"Validation dataset size: {len(X_val)} images")
print(f"Test dataset size: {len(X_test)} images")

print(f"Train/Val size: {len(X_train_val)}, Test size: {len(X_test)}")
print(f"Train size: {len(X_train)}, Val size: {len(X_val)}")

print(X_train[0])

"""## Data Preprocessing"""

# Normalize images
X_train = X_train.astype('float32') / 255.0
X_val = X_val.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0

print(original_images.shape)
print(augmented_images.shape)

import matplotlib.pyplot as plt

# Display a few training images
for i in range(5):
    plt.imshow(X_train[i])
    plt.title(f"Label: {y_train[i]}")
    plt.show()

# One-hot encode the labels
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder
y_train = to_categorical(y_train, num_classes=4)
y_val = to_categorical(y_val, num_classes=4)
y_test = to_categorical(y_test, num_classes=4)